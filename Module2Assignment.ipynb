{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXr/TXAgnI0CkOg3v9RwR3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AirPro/DeepLearning/blob/Module2Assignment/Module2Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module Two Hands On Assignment\n",
        "January 25, 2023 <br>\n",
        "By: Robert Freid for Deep Learning Class"
      ],
      "metadata": {
        "id": "sa5mmL-WdLVQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BKWKDbobcvE0"
      },
      "outputs": [],
      "source": [
        "# import modules and libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the Fashion MNIST dataset named fashion_mnist\n",
        "Load the data from Repository <br>\n",
        "Display the shape ofnthe dataset"
      ],
      "metadata": {
        "id": "2EhrObifeqgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the Fashion_Mnist dataset from Keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Save the training set in X_Train and X_Test and the testing data in y_train and y_test\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# display the shape of the imported dataset\n",
        "print(\"X_train shape = \", X_train.shape)\n",
        "print(\"y_train shape = \", y_train.shape)\n",
        "print(\"X_test shape = \", X_test.shape)\n",
        "print(\"y_test shape = \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9rmd6CQgTXm",
        "outputId": "0cd240fd-cd4d-4c37-b52e-1390d06cb600"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape =  (60000, 28, 28)\n",
            "y_train shape =  (60000,)\n",
            "X_test shape =  (10000, 28, 28)\n",
            "y_test shape =  (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the image at location 2351 in the dataset using the pyplot library."
      ],
      "metadata": {
        "id": "AzELaeBitODk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image at location 2351\n",
        "plt.imshow(X_train[2351], cmap = plt.get_cmap('gray'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "KFvZcBXxtfCA",
        "outputId": "493b6f9b-0308-40b8-9344-1200ad8a01ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9b0238dbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform the requirement to preprocess the dataset"
      ],
      "metadata": {
        "id": "BKuH-yBu2Dh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change integers to 32-bit floating point numbers\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalize each value for each pixel for the entire vector for each input\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Reshape the datasets which allows adding or removing demensions in an array\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000, 28,28,1)\n",
        "\n",
        "# Verify using print fuction datasets\n",
        "print(\"Training matrix shape: \", X_train.shape)\n",
        "print(\"Testing matrix shape: \", X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMv1RNgV2KUx",
        "outputId": "e7f77f7a-0425-4335-8746-7b2d0f82dfc3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matrix shape:  (60000, 28, 28, 1)\n",
            "Testing matrix shape:  (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the labels by converting them to one-hot-encoder\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# number of unique digits in the MNIST dataset\n",
        "nb_classes = 10\n",
        "\n",
        "# convert the Y_train and y_test to one-hot-encoding\n",
        "y_train = np_utils.to_categorical(y_train, nb_classes )\n",
        "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "# display the shape of the converted datasets\n",
        "print(\"Training labels shape: \", y_train.shape)\n",
        "print(\"Testing labels shape: \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXATbVkz4BW9",
        "outputId": "b5c78168-31c0-4854-8ddc-fdccc384dab4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training labels shape:  (60000, 10)\n",
            "Testing labels shape:  (10000, 10)\n"
          ]
        }
      ]
    }
  ]
}